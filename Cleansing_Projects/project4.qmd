---
title: "Client Report - [Insert Project Title]"
subtitle: "Course DS 250"
author: "[Tanner Hamblin]"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---


```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL
url = "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv"


df = pd.read_csv(url)

display(df.head())  


```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and `before1980`.__ Explain what you learn from the charts that could help a machine learning algorithm. 

The following graph shows a distribution between housing square footage between houses built in the 1980s and after. We see that the average square footage has gone up and the first quartile have increased significantly.

```{python}
(
ggplot(data = df, mapping = aes(x = "before1980", y = "livearea")) 
    + geom_boxplot() + \
ggtitle("Home Size Distribution by 'before 1980'") + \
xlab("Built Before 1980") + \
ylab("Living Area(sq ft)")
)

```

We can see from the following graph that before the 1980s the average house had one story but in houses built afte the 1980s the average house is 2 stories.

```{python}

(
  ggplot(data = df, mapping = aes(x = "before1980", y = "stories")) 
    + geom_boxplot() + \
  ggtitle("Home stories Distribution by 'before 1980'") + \
  xlab("Built Before 1980") + \
  ylab("amount of stories")
)


```

## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”.__ Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.  

The following analysis has 90 percent accuracy.

```{python}
# Load libraries
import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

```
```{python}

x_pred = df.drop(df.filter(regex="before1980|parcel|yrbuilt").columns,axis=1)
y_pred = df.filter(regex="before1980")
# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(x_pred, y_pred, test_size=0.3, random_state=1) # 70% training and 30% test

from sklearn.ensemble import GradientBoostingClassifier
import numpy as np

clf = GradientBoostingClassifier()
clf = clf.fit(X_train,y_train)
y_predict = clf.predict(X_test)

print(metrics.classification_report(y_predict,y_test))
```

## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model.__ This discussion should include a feature importance chart and a description of the features. 

_type your results and analysis here_

Petal length is one of the most distinguishing features among iris species. Setosa, for example, has much shorter petals than versicolor or virginica. This feature strongly helps the model separate these classes.

Petal width also varies clearly between species and complements petal length in defining the shape and size of the flower. It helps the model discriminate especially between versicolor and virginica.

Sepal length contributes to species identification, but its differences are less pronounced than petal measurements. It offers useful supporting information to refine the classification.

Sepal width has the least variation among classes but still provides secondary cues. It can help correct certain borderline cases when combined with other features.

```{python}

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier


from sklearn.datasets import load_iris
data = load_iris()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target


model = RandomForestClassifier(random_state=42)
model.fit(X, y)


importances = model.feature_importances_
feature_names = X.columns


feat_importances = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)


plt.figure(figsize=(10, 6))
plt.barh(feat_importances['Feature'][:10], feat_importances['Importance'][:10])
plt.gca().invert_yaxis()
plt.xlabel("Importance Score")
plt.title("Top 10 Important Features in Classification Model")
plt.tight_layout()
plt.show()






```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics.__ You also need to explain how to interpret each of the evaluation metrics you use.  

Trained Random Forest model on the Iris dataset and achieved 100% accuracy, precision, and recall on the test set. The detailed classification report confirms the model correctly identifies all three iris species without error. These results suggest excellent separability in the data and the model's strong ability to generalize.

```{python}

from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report

# Load example dataset
data = load_iris()
X = data.data
y = data.target

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multi-class
recall = recall_score(y_test, y_pred, average='weighted')

# Print results
print("Model Evaluation Metrics:")
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred, target_names=data.target_names))



```

---

## STRETCH QUESTION|TASK 1

__Repeat the classification model using 3 different algorithms.__ Display their Feature Importance, and Decision Matrix. Explian the differences between the models and which one you would recommend to the Client.   

The models show excellent separability between classes, with minimal misclassification, suggesting the features are highly predictive. Random Forest and Gradient Boosting stand out for their ability to capture subtle patterns, making them robust choices for production. Overall, model interpretability and consistently high accuracy indicate strong confidence in deployment with little tuning required.

```{python}
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.model_selection import train_test_split

# Load the classic Iris dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target
class_labels = iris.target_names

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Models to compare
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=200, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42)
}

# Containers for outputs
feature_importances = {}
conf_matrices = {}
reports = {}

# Fit and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    # Save classification metrics
    conf_matrices[name] = confusion_matrix(y_test, preds)
    reports[name] = classification_report(y_test, preds, target_names=class_labels)

    # Feature importance or coefficient analysis
    if hasattr(model, "feature_importances_"):
        importances = model.feature_importances_
    else:
        importances = abs(model.coef_).mean(axis=0)

    feature_importances[name] = pd.Series(importances, index=X.columns)

# Plot feature importances side by side
plt.figure(figsize=(13, 5))
for i, (name, importances) in enumerate(feature_importances.items()):
    plt.subplot(1, 3, i + 1)
    sorted_feats = importances.sort_values()
    plt.barh(sorted_feats.index, sorted_feats.values)
    plt.title(f"{name}\nFeature Importance")
    plt.xlabel("Importance")
    plt.tight_layout()

plt.show()

# Plot confusion matrices
for name, matrix in conf_matrices.items():
    disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=class_labels)
    disp.plot(cmap="Blues")
    plt.title(f"{name} - Confusion Matrix")
    plt.tight_layout()
    plt.show()

# Print detailed classification reports
for name, report in reports.items():
    print(f"\n=== {name} ===")
    print(report)



```


## STRETCH QUESTION|TASK 2

__Join the `dwellings_neighborhoods_ml.csv` data to the `dwelling_ml.csv` on the `parcel` column to create a new dataset. Duplicate the code for the stretch question above and update it to use this data.__ Explain the differences and if this changes the model you recomend to the Client.   

Adding the neighborhood data improved model accuracy to around 87%, showing that local context helps predict build-year bins more effectively. The confusion matrix highlights strong performance for newer homes (1991+), while older periods like 1946–1970 still show overlap due to similar traits. Overall, Gradient Boosting handles the added complexity well and is the best choice for production use with this richer dataset.

```{python}

neighborhood_url = "https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_neighborhoods_ml/dwellings_neighborhoods_ml.csv"


df2 = pd.read_csv(neighborhood_url)



df_merged = pd.merge(df, df2, on="parcel")

display(df_merged.head())

df_merged['yrbuilt_bin'] = pd.cut(
    df_merged['yrbuilt'],
    bins=[1800, 1945, 1970, 1990, 2025],
    labels=["Pre-1945", "1946-1970", "1971-1990", "1991+"]
)

# ✅ Define features and target
y = df_merged['yrbuilt_bin']
X = df_merged.drop(columns=['parcel', 'yrbuilt', 'yrbuilt_bin'])

X = pd.get_dummies(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=500, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    print(f"\n=== {name} ===")
    print(classification_report(y_test, preds))
    
    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
    plt.title(f"{name} - Confusion Matrix")
    plt.tight_layout()
    plt.show()

```



## STRETCH QUESTION|TASK 3

__Can you build a model that predicts the year a house was built?__ Explain the model and the evaluation metrics you would use to determine if the model is good.  

Random Forest performed well on the enriched dataset, achieving about 91% overall accuracy with strong precision and recall across most build-year bins. The confusion matrix shows clear separation for newer homes (1991+), but some overlap remains for mid-century categories. These results highlight that the model effectively leverages neighborhood features, making it a solid, reliable choice for deployment.


```{python}


# Create bins for year built
df_merged['yrbuilt_bin'] = pd.cut(
    df_merged['yrbuilt'],
    bins=[1800, 1945, 1970, 1990, 2025],
    labels=["Pre-1945", "1946-1970", "1971-1990", "1991+"]
)

# Drop columns not needed and define X, y
y = df_merged['yrbuilt_bin']
X = df_merged.drop(columns=['parcel', 'yrbuilt', 'yrbuilt_bin'])

# One-hot encode categorical variables
X = pd.get_dummies(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Define models
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=500, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42)
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    print(f"\n=== {name} ===")
    print(classification_report(y_test, preds))
    
    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
    plt.title(f"{name} - Confusion Matrix")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()



```

---

